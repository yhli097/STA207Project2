---
title: "Project 2: Project STAR II"
output:
  pdf_document: default
  html_document:
    df_print: paged
    fig_caption: yes
    number_sections: yes
  date: "01/31/2020"
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,message=FALSE,warning=FALSE)
```
***
This Document is the project 2 of Team 7 in STA 207, Winter 2020.

# Group Partners:

1. Bingdao Chen bdchen@ucdavis.edu contribution: explore data and test causal effect

2. Yahui Li yhuli@ucdavis.edu contribution: write down and hold one-way ANOVA model

3. Zihan Wang zihwang@ucdavis.edu contribution: test on difference

4. Jian Shi jnshi@ucdavis.edu contribution: model diagnose

The repository in Github is on https://github.com/yhli097/STA207Project2.git

***

# Introduction

## Background

Tennesses Student/Teacher Achievement Ratio study (Project STAR) was conducted in the late 1980s to evaluate the effect of class size on test scores. The study randomly assigned students to small classes, regular classes, and regular classes with a teacher’s aide. In order to randomize properly, schools were enrolled only if they had enough studybody to have at least one class of each type. Once the schools were enrolled, students were randomly assigned to the three types of classes, and one teacher was randomly assigned to one class.

The primary scientific question of interest is whether there is a treatment effect of class types on math scaled scores across teachers in 1st grade, with the school indicator as the other factor. In this study, we implement exploratory data analysis, two-way anova model, model diagnostics, hypothesis testing. In the end, we conclude our findings and discuss any causal statements that could possibly be made based on our analysis and assumptions, and compare the results between Project 2 and Project 1.

## Statistical questions of interest

To answer the primary scientific question of interest, we propose to fit a two-factors anova model with the quantitative test scores grouped by teacher as the response variable and the class type as well as school as the predictor variable. We will then run our model diagonstics to see if the assumptions of the model hold and test whether or not there is a treatment effect on the test scores.


# Analysis Plan

## Population and study design

According to the description of the dataset, over 7,000 students in 76 schools were randomly assigned into one of three different treatments: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher’s aide). Classroom teachers were also randomly assigned to the classes they would teach. We will only focus on the data about the 1st grade students as study targets[1].

## Descriptive Analysis

First of all, we will pick up all valuable variables we are interested in. To deal with missing value, we will draw plots to show the percentage of missing value for these variables, then decide whether drop the missing value or not. We will then explore the math scores grouped by teacher ID. To choose the summary information on math scores in each unit, we will plot different distributions to find a statistic which is the most informative as well as normal-like. In the end, we study the treatment of class type as well as school ID. Based on different class type as well as school ID, we will draw box plot on math score and check if there is any difference in different treament. 

## Two-way Anova Model

In order to investigate whether there are effects of class types on math scaled scores in 1st grade and minimize the effects of systematic error, randomized block design is uesd, and we will creat blocks by different schools. Within blocks, students and teachers are randomly assigned to class in different types. Therefore, it is possible to assess the effect from different levels of class types without worry about the influence from different schools. Although there are two factors in this experiment, we are not interested in the effect from different class type as well as different school. As a result, interaction term in this model should be excluded.

The two-way ANOVA model for a randomized block design is shown as below:
$$Y_{ijk} = \mu + \tau_{i}+ \beta_{j}+\epsilon_{ijk}, \quad\text{with}\quad \epsilon_{ijk} \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2).$$

By notation,

* The index $i$ denotes main factor level. There are 3 levels about class type: `small`, `regular` and `rugular+aid`. The index $j$ denotes blocking factor level. There are 76 levels about different school ID. The index $k$ denotes experimental unit, about mean score of $k$-th teachers in 1st grade.

* $Y_{ijk}$ refers to the mean math score for $k$-th teacher ID in  $i$-th type of class and $j$-th school ID. $\mu$ denotes the overall mean value of the mean math scores in 1st grade for all treatments. $\tau_{i}$ denotes main effect of level $i$ from the class type factor. $\beta{j}$ denotes blocking effect of level $j$ from the school ID factor.
$\epsilon_{ijk}$ denotes random errors. 


Moreover, there is a "sum-to-zero" constraint shown in the following :

$$\sum_i \tau_{i} = \sum_j \beta_j = 0$$

Assumptions of two-way ANOVA model specified as follows:

* the mean of the response variable is influenced additively (if not interaction term) and linearly by the factors;
* The random errors are assumed to be identically and independently distributed from a normal distribution with mean $0$ and variance $\sigma^2$.

## Model Diagnostics

This part will check the assumptions of our one-way ANOVA model so that this model is appropriate. To verify the independence assumption, we would analyze the experiment design to check the randomization of the samples. For the residuals, we would use the residuals v.s. fitted values plot to check equal variance assumption. Then, Q-Q plot is drawn to check whether the residuals are normally distributed or not.

## Hypothesis Testing

In this part, in order to investigate whether there is a treatment effect based on class types, we decide to use F-test. Moreover, if there is a treatment effect, we will investigate comparisons between two different class types. Because our dataset is unbalanced for each group, Tukey’s Procedure is the best method to test among Tukey, Bonferroni and Scheffe. Moreover, Tukey’s Procedure has the smallest T-statistics, which means it has the narrowest confidence interval, then it can give a more precise estimation of the difference.

# Results

## Descriptive Analysis

The dataset we investigate has 11601 rows and 379 cloumns, and we choose four variables: `g1classtype`, `g1schid`, `g1tchid`, `g1tmathss` which are related with math scaled scores in the 1st grade. `g1classtype` represents the class type of students in 1st grade. `g1schid` represents school ID. `g1tchid` represents teacher ID. `g1tmathss` represents math scaled scores of students in 1st grade. Figure1 shows the basic information of four variables.

```{r}
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(gridExtra)
library(ggpubr)
load("./STAR_Students.RData")
data <- data.frame(g1classtype = x$g1classtype, g1schid = x$g1schid, 
                   g1tchid = x$g1tchid, g1tmathss = x$g1tmathss)
```


```{r}
# Table code
varsum <- data.frame(Name= c("g1classtype", "g1schid", "g1tchid", "g1tmathss"),
                     Type= c("qualitative variable", "qualitative variable", "qualitative variable", "quantitive variable"), 
                     "The number of levels"= c(3,76,339,NA))
kable(varsum,caption = "Table 1: basic information of variables") %>%
  kable_styling(bootstrap_options = "striped", full_width = F )
```

In Figure 1, the above plot shows the percentage of missing value of four variables are nearly same, and the plot below shows that the location of missing values for three qualitative variables are consistent. It can be explained that because of low grades in kindergarten in STAR project, students quit STAR project and go to another school, or they join STAR project after 1st grade. Because we don't know how to tackle missing values, considering that we have enough data and believe that it won't have the significant impact on the results, we drop them directly.

```{r}
#Code for the first plot
missing.values <- data %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)

levels <-
    (missing.values  %>% filter(isna == T) %>% arrange(desc(pct)))$key

percentage.plot <- missing.values %>%
      ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), 
                 stat = 'identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
      coord_flip() +
      labs(title = "Figure 1: Percentage of missing values", x =
             'Variable', y = "% of missing values")

#Code for the second plot
row.plot <- data %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato3'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Variable",
           y = "Row Number", title = "Missing values in rows") +
    coord_flip()


#arrange them
grid.arrange(percentage.plot, row.plot, ncol = 2)
```

```{r}
#remove NA
data <- na.omit(data)
data$g1schid <- factor(data$g1schid)
data$g1tchid <- factor(data$g1tchid)
```


In this project, we are interested in math scaled scores in the 1st grade with teachers as the unit. After verifying each teacher are only employed in specific school and teach one specific class type, we select the mean of math scaled scores of one particular class to judge teachers. Therefore, we have a new dataset which has 339 rows and four columns including g1classtype, g1schid, g1tchid and mean. Figure 2 shows the distribution of the mean of math score by different teacher. It is bell-shaped and roughly closed to normal distribution.

```{r}
data_by_teacher <- data %>%
  group_by(g1classtype,g1schid,g1tchid) %>%
  summarize(mean = mean(g1tmathss))

ggplot(data_by_teacher, aes(x=mean)) + 
  geom_histogram() +
  ggtitle("Figure 2: the mean of math score by different teacher")

```

Figure 3 shows the frequency number of class type and school id. Due to too many levels in g1schid, x axis labels in the plot of g1schid is omitted for readability. We can find that  g1classtype data is roughly balanced, and there is one specific school whose frequency number which is much higher than rest of schools. Figure 4 shows that the frequency number of class of different types in each school. Excepts a few extremely cases, data is more balanced than data group by class type. 

```{r}
# Figure 3
classbar <- ggplot(data_by_teacher, aes(g1classtype)) +
  geom_bar(fill = "#0073C2FF") +
  theme_pubclean() +
  ggtitle("Figure 3: The frequency bar plots of class type and school id")


schoolbar <- ggplot(data_by_teacher, aes(x=reorder(g1schid, -table(g1schid)[g1schid]))) +
  geom_bar(fill = "#0073C2FF") +
  theme_pubclean() +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "g1schid")


grid.arrange(classbar, schoolbar, nrow = 2) 
```

```{r}
# Figure 4 Bar plots of contingency tables
ggplot(data_by_teacher %>%
  group_by(g1classtype, g1schid) %>%
  count(), aes(x = g1schid, y = n))+
  geom_bar(
    aes(fill = g1classtype), stat = "identity", color = "white",
    position = position_dodge(0.9)) +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "g1schid") +
  ggtitle("Figure 4: The frequency bar plots of grouped contingency tables")

```

In Figure 5, it can be seen that different class types have effects on mean scores of math. Therein, teachers in small class have the higher mean scores of math and teachers in regular class have the lower mean scores of math in general. Also, different schools have impacts on mean scores of math. Aming to investigate the class types effect on mean scores of math, it is a good strategy that using schools to creat blocks for eliminating effects between different schools. 

```{r}

classbox <- ggplot(data_by_teacher, aes(x=g1classtype, y=mean)) + 
    geom_boxplot(fill="slateblue", alpha=0.2) +
    labs(title = "Figure 5: The distribution of mean scores of math by class type and school id")


schoolbox <- ggplot(data_by_teacher, aes(x=g1schid, y=mean)) + 
    geom_boxplot(fill="slateblue", alpha=0.2) +
    theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "g1schid") 

grid.arrange(classbox, schoolbox, ncol = 2) 
```


## Two-way ANOVA Model

Table 2 shows a summary of our anova model. The mean of square among class types is 5809 while that among school is 1824. As is known that the larger the mean of square is, the larger the variability among the group is. Therefore, the variability of mean math score in different class types is much larger than that in different school. In addition, the mean of square of residuals is 277, which is much smaller compared with class types and school. And the p-values of the two variables are much smaller than 0.001, which are highly significant in statistics.


**Table 2. ANOVA Table**

|Source of Variation | Degree of Freedom | Sum Square | Mean Square | F value | P value |
|-------|-------|------|-----|--------|----------|
|g1classtype| 2          |11617  |  5809 | 20.991| 3.52e-09 |
|g1schid     | 75 | 136833   | 1824  | 6.593 | < 2e-16 |
|Residuals  | 261 | 72225  |   277                     |




## Model Diagnostics

In this experiment, researchers assigned students to small classes, regular classed and regular classes with aide randomly. Besides, teachers are also randomly assigned to classed in each school. By adding the randomized block design of schools in the experiment, there are adepuate reasons to believe that the outcomes do not denpend on each other. In other words, the model satisfies the independence assumption.

From the Residuals vs Fitted Values scatterpoint (Figure 6), these points are uniformly distributed on both sides of x-axis, which means that our model does not violate the equal variance assumption. The Normal Q-Q plot (Figure 7) illustrates that the residuals are slightly heavy-tailed, but given the large sample size, we can verify that our model meet the normality assumption with central limit theorem.
```{r}
library(stats);library(car);
#check the mean zero and equal variance
anova.fit<-aov(mean ~ g1classtype + g1schid,data = data_by_teacher)
par(mfrow=c(1,2))
plot(anova.fit, which = 1, main = "Figure 6: Residuals vs Fitted Values plot")#figure 6
plot(anova.fit, which = 2, main = "Figure 7: Normal Q-Q plot")#figure 6
par(mfrow=c(1,1))
```

## Hypothesis Testing

For F-test part, to test null hypothesis $H_0:\mu_1=\mu_2=\mu_3$ against alternative hypothesis: not all $H_a:\mu_{i}$'s are equal. We compute F-statistic: $F^*=\frac{MSTR}{MSE}=20.991$ and $F(0.95,2,6597)=2.997093$. Since $F^*>F(0.95,2,6597)$, We can reject the null hypothesis at the significance level 0.05. We can claim that there exists a treatment effect based on class types.

For Tukey’s Procedure part, we use Tukey’s Procedure to test difference between each groups on class types. From the figure1, we can get the confidence intervals for all three pairs of class types. 

As we can see, 0 is in the 95% family-wise confidence interval of the difference between regular aide class and regular class. It means that the difference between these two groups is really small and it is close to 0. From the table 1, we can find that regular class and small class have the largest difference. Teachers who are teaching in small class have 13.58 scores higher than regular class on the average. And regular aide class and regular class have the smallest difference.  

```{r}
alpha=0.05;
T.ci=TukeyHSD(anova.fit,conf.level = 1-alpha)
par(mfrow=c(1,1))
plot(T.ci, las=1 , col="brown") #to huige：cannot remove 2nd plot
T.ci$g1classtype
```


## Causal Analysis
In this part, we use average treatment effect to measure the causal effect. We can make causal statements if it follows two assumptions: 

***Stable unit treatment value assumption***: The potential outcomes for any unit do not vary with the treatments assigned to other units, and, for each unit, there are no different forms or versions of each treatments level, which lead to different potential outcomes.

***Ignorability***: Treatment assignment is independent of the outcomes.


For the first assumption, it means that we could exclude the probability that a teacher was assigned or not assigned to small class does not affect the mean of math grade in other class types. Also, same version of treatment need to be ensured, that means teachers in the class of the one specific type give consistent education of that class type. From the background of project STAR, we know that it is randomized experiment since it randomly assigns students to different class types and teachers are also randomly assigned to class types. Therefore, both of two points are hold based on the setting of the experiment. However, for the second assumptions, treatment assignment is not independent of the outcomes. Since project STAR is a randomized block design but not a completely randomized design. Students and teachers are only randomized in each block and are not randomly assigned to schools. Therefore, treatment assignment and the outcomes are not independent. We can't make any causal statements due to violating Ignorability assumption. 


# Difference between two projects

In project 1, we assume the experiment to be completely randomized design. That is, only class type itself effects the math scores in 1st grade. Other factors like gender, lunch are randomized in this experiment don't affect treatment. And then we use one-way ANOVA model to investigate it. In project 2, we regard this experiment as randomized block design and use school as block, which is closer to the real world. We take account of schools' effects and build a two-way ANOVA model to investigate the class types' effects on math scores.

In terms of the results, in project 1, we obtain that all of pairwise comparisons of math scores in three class types are statistically significant difference. In project 2, we can't make a claim that there is a statistically significant difference between the math scores in regular class and regular with aid class. This difference may be caused by different statistics served as the value of outcome in experiment's setting. More important, in project 2, blocking strategy can mitigate the effects of systematic error. From the data exploration, different schools also affect math scores due to educational resources differences. Within blocks, it is possible to assess the effect of different levels of the class types without having to worry about variations due to different schools. 

Moreover, for causal inference, we make some causal statements in project 1, but us fails to make any causal statements in project 2. Because when using average treatment effect to measure the causal effect, Ignorability assumption are only satisfied in completely randomized experiment. In randomized block design, treatment assignment is no longer independent of the outcomes.


# Discussion



# Appendix I. Reference

[1] C.M. Achilles; Helen Pate Bain; Fred Bellott; Jayne Boyd-Zaharias; Jeremy Finn; John Folger; John Johnston; Elizabeth Word, 2008, “Tennessee’s Student Teacher Achievement Ratio (STAR) project”, https://doi.org/10.7910/DVN/SIWH9F, Harvard Dataverse, V1, UNF:3:Ji2Q+9HCCZAbw3csOdMNdA== [fileUNF]

# Appendix II. Session information
```{r}
print(sessionInfo(), local = FALSE)
```
