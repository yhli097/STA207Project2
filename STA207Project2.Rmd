---
title: "Project 2: Project STAR II"
output:
  html_document:
    df_print: paged
    fig_caption: yes
    number_sections: yes
  pdf_document: default
  date: "01/31/2020"
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,message=FALSE,warning=FALSE)
```
***
Note: The report might be shown to the class as examples if it is done well very or very badly, with your identity redacted. 

***
This Document is the project 2 of Team 7 in STA 207, Winter 2020.

# Group Partners:

1. Bingdao Chen bdchen@ucdavis.edu contribution: explore data and test causal effect

2. Yahui Li yhuli@ucdavis.edu contribution: write down and hold one-way ANOVA model

3. Zihan Wang zihwang@ucdavis.edu contribution: test on difference

4. Jian Shi jnshi@ucdavis.edu contribution: model diagnose

The repository in Github is on https://github.com/yhli097/STA207Project2.git

***

# Introduction

## Background

Tennesses Student/Teacher Achievement Ratio study (Project STAR) was conducted in the late 1980s to evaluate the effect of class size on test scores. The study randomly assigned students to small classes, regular classes, and regular classes with a teacher’s aide. In order to randomize properly, schools were enrolled only if they had enough studybody to have at least one class of each type. Once the schools were enrolled, students were randomly assigned to the three types of classes, and one teacher was randomly assigned to one class.

The primary scientific question of interest is whether there is a treatment effect of class types on math scaled scores across teachers in 1st grade, with the school indicator as the other factor. In this study, we implement exploratory data analysis, two-way anova model, model diagnostics, hypothesis testing. In the end, we conclude our findings and discuss any causal statements that could possibly be made based on our analysis and assumptions, and compare the results between Project 2 and Project 1.

## Statistical questions of interest

To answer the primary scientific question of interest, we propose to fit a two-factors anova model with the quantitative test scores grouped by teacher as the response variable and the class type as well as school as the predictor variable. We will then run our model diagonstics to see if the assumptions of the model hold and test whether or not there is a treatment effect on the test scores.


# Analysis Plan


## Population and study design

According to the description of the dataset, over 7,000 students in 76 schools were randomly assigned into one of three different treatments: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher’s aide). Classroom teachers were also randomly assigned to the classes they would teach. We will only focus on the data about the 1st grade students as study targets[1].

## Descriptive Analysis

First of all, we will pick up all valuable variables we are interested in. To deal with missing value, we will draw plots to show the percentage of missing value for these variables, then decide whether drop the missing value or not. 

We will then explore the math scores grouped by teacher ID. To choose the summary information on math scores in each unit, we will plot different distributions to find a statistic which is the most informative as well as normal-like. 

In the end, we study the treatment of class type as well as school ID. 
Based on different class type as well as school ID, we will confirm whether there is any difference on math scores across teachers not. 


## Two-way Anova Model

In order to investigate whether there are effects of class types on math scaled scores in 1st grade and minimize the effects of systematic error, randomized block design is uesd, and we will creat blocks by different schools. Within blocks, students and teachers are randomly assigned to class in different types. Therefore, it is possible to assess the effect from different levels of class types without worry about the influence from different schools. Although there are two factors in this experiment, we are not interested in the effect from different class type as well as different school. As a result, interaction term in this model should be excluded.

The two-way ANOVA model for a randomized block design is shown as below:

$$Y_{ijk} = \mu + \tau_{i}+ \beta_{j}+\epsilon_{ijk}, \quad\text{with}\quad \epsilon_{ijk} \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2).$$

By notation,

* The index $i$ denotes main factor level. There are 3 levels about class type: `small`, `regular` and `rugular+aid`.

* The index $j$ denotes blocking factor level. There are 76 levels about different school ID.

* The index $k$ denotes experimental unit, about mean score of $k$-th teachers in 1st grade. $n_{ij}$ is the number of experimental units in treatment $(i,j)$ from both factors.

* $Y_{ijk}$ refers to the mean math score for $k$-th teacher ID in  $i$-th type of class and $j$-th school ID.

* $\mu$ denotes the overall mean value of the mean math scores in 1st grade for all treatments.

* $\tau_{i}$ denotes main effect of level $i$ from the class type factor.

* $\beta{j}$ denotes blocking effect of level $j$ from the school ID factor.

* $\epsilon_{ijk}$ denotes random errors. 


Moreover, there is a "sum-to-zero" constraint shown in the following :

$$\sum_i \tau_{i} = \sum_j \beta_j = 0$$

Assumptions of two-way ANOVA model specified as follows:

* the mean of the response variable is influenced additively (if not interaction term) and linearly by the factors;

* The random errors are assumed to be identically and independently distributed from a normal distribution with mean $0$ and variance $\sigma^2$.

## Model Diagnostics



# Results

<span style="color:red">Note: </span> In this template, we present the unpolished tables and figures generated with generic `r` functions, and we skip all interpretation of the analysis results and the sensitivity analysis.  You can adapt any functions in this section in your report.

## Descriptive Analysis

The dataset we investigate has 11601 rows and 379 cloumns, and we narrow it down to four columns, that is, g1classtype, g1schid, g1tchid, g1tmathss which are related with math scaled scores in the 1st grade. g1classtype represents the class type of students in 1st grade. g1schid represents school’s id. g1tchid represents teacher’s id. g1tmathss represents math scaled scores of students in 1st grade. Figure1 shows the basic information of four variables.

```{r}
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(gridExtra)
library(ggpubr)
load("./STAR_Students.RData")
data <- data.frame(g1classtype = x$g1classtype, g1schid = x$g1schid, 
                   g1tchid = x$g1tchid, g1tmathss = x$g1tmathss)
```


```{r}
# Table code
varsum <- data.frame(Name= c("g1classtype", "g1schid", "g1tchid", "g1tmathss"),
                     Type= c("qualitative variable", "qualitative variable", "qualitative variable", "quantitive variable"), 
                     "The number of levels"= c(3,76,339,NA))
kable(varsum,caption = "Table 1: basic information of variables") %>%
  kable_styling(bootstrap_options = "striped", full_width = F )
```

In Figure 1, the above plot shows the percentage of missing value of four variables are nearly same, and the plot below shows that the location of missing values for three qualitative variables are consistent. It can be explained that because of low grades in kindergarten in STAR project, students quit STAR project and go to another school, or they join STAR project after 1st grade. Because we don't know how to tackle missing values, considering that we have enough data and believe that it won't have the significant impact on the results, we drop them directly.

```{r}
#Code for the first plot
missing.values <- data %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)

levels <-
    (missing.values  %>% filter(isna == T) %>% arrange(desc(pct)))$key

percentage.plot <- missing.values %>%
      ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), 
                 stat = 'identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
      coord_flip() +
      labs(title = "Figure 1: Percentage of missing values", x =
             'Variable', y = "% of missing values")

#Code for the second plot
row.plot <- data %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato3'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Variable",
           y = "Row Number", title = "Missing values in rows") +
    coord_flip()


#arrange them
grid.arrange(percentage.plot, row.plot, ncol = 2)
```

```{r}
#remove NA
data <- na.omit(data)
data$g1schid <- factor(data$g1schid)
data$g1tchid <- factor(data$g1tchid)
```


In this project, we are interested in math scaled scores in the 1st grade with teachers as the unit. After verifying each teacher are only employed in specific school and teach one specific class type, we select the mean of math scaled scores of one particular class to judge teachers. Therefore, we have a new dataset which has 339 rows and four columns including g1classtype, g1schid, g1tchid and mean. Figure 2 shows the distribution of the mean of math score by different teacher. It is bell-shaped and roughly closed to normal distribution.

```{r}
data_by_teacher <- data %>%
  group_by(g1classtype,g1schid,g1tchid) %>%
  summarize(mean = mean(g1tmathss))

ggplot(data_by_teacher, aes(x=mean)) + 
  geom_histogram() +
  ggtitle("Figure 2: the mean of math score by different teacher")

```

Figure 3 shows the frequency number of class type and school id. Due to too many levels in g1schid, x axis labels in the plot of g1schid is omitted for readability. We can find that  g1classtype data is roughly balanced, and there is one specific school whose frequency number which is much higher than rest of schools. Figure 4 shows that the frequency number of class of different types in each school. Excepts a few extremely cases, data is more balanced than data group by class type. 

```{r}
# Figure 3
classbar <- ggplot(data_by_teacher, aes(g1classtype)) +
  geom_bar(fill = "#0073C2FF") +
  theme_pubclean() +
  ggtitle("Figure 3: The frequency bar plots of class type and school id")


schoolbar <- ggplot(data_by_teacher, aes(x=reorder(g1schid, -table(g1schid)[g1schid]))) +
  geom_bar(fill = "#0073C2FF") +
  theme_pubclean() +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "g1schid")


grid.arrange(classbar, schoolbar, nrow = 2) 
```

```{r}
# Figure 4 Bar plots of contingency tables
ggplot(data_by_teacher %>%
  group_by(g1classtype, g1schid) %>%
  count(), aes(x = g1schid, y = n))+
  geom_bar(
    aes(fill = g1classtype), stat = "identity", color = "white",
    position = position_dodge(0.9)) +
  theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "g1schid") +
  ggtitle("Figure 4: The frequency bar plots of grouped contingency tables")

```

In Figure 5, it can be seen that different class types have effects on mean scores of math. Therein, teachers in small class have the higher mean scores of math and teachers in regular class have the lower mean scores of math in general. Also, different schools have impacts on mean scores of math. Aming to investigate the class types effect on mean scores of math, it is a good strategy that using schools to creat blocks for eliminating effects between different schools. 

```{r}

classbox <- ggplot(data_by_teacher, aes(x=g1classtype, y=mean)) + 
    geom_boxplot(fill="slateblue", alpha=0.2) +
    labs(title = "Figure 5: The distribution of mean scores of math by class type and school id")


schoolbox <- ggplot(data_by_teacher, aes(x=g1schid, y=mean)) + 
    geom_boxplot(fill="slateblue", alpha=0.2) +
    theme(
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) +
  labs(x = "g1schid") 

grid.arrange(classbox, schoolbox, ncol = 2) 
```


## Two-way ANOVA Model

**Table . ANOVA Table**

|Source of Variation | Degree of Freedom | Sum Square | Mean Square | F value | P value |
|-------|-------|------|-----|--------|----------|
|g1classtype| 2          |11617  |  5809 | 20.991| 3.52e-09 |
|g1schid     | 75 | 136833   | 1824  | 6.593 | < 2e-16 |
|Residuals  | 261 | 72225  |   277                     |




## Model Diagnostics

In this experiment, researchers assigned students to small classes, regular classed and regular classes with aide randomly. Besides, teachers are also randomly assigned to classed in each school. By adding the randomized block design of schools in the experiment, there are adepuate reasons to believe that the outcomes do not denpend on each other. In other words, the model satisfies the independence assumption.

From the Residuals vs Fitted Values scatterpoint, these points are uniformly distributed on both sides of x-axis, which means that our model does not violate the equal variance assumption.

```{r}
library(stats);library(car);
#check the mean zero and equal variance
anova.fit<-aov(mean ~ g1classtype + g1schid,data = data_by_teacher)
plot(anova.fit, which = c(1,3))
summary(anova.fit)



leveneTest(mean ~ g1classtype*g1schid,data = data_by_teacher)
```

The Normal Q-Q plot illustrates that the residuals are heavy tailed compared with the normal distribution. In order to check the normality assumption more precisely, we conduct the Shapiro-Wilk Normality Test, whose null hypothesis is $H_0:$the popluation is normally distributed. The result shows that $W=0.9802$ and the $p-value$ is 0.0001, which is much smaller than the significant level 0.01. Therefore, we are 99% confident to reject the null hypothesis $H_0:$the residuals is normally distributed and our model does not follow the normality assumption.

```{r}
#normality assumption
plot(anova.fit, which = 2)

shapiro.test(anova.fit$residuals)
```


The model diagnostic part will confirm whether the model asssumptions of the two-way ANOVA model so that it is appropriate for the problem setting. For the residuals, we will use the residuals vs fitted values plot to check equal variance assumption. Then, Q-Q plot is drawn to see whether the residuals are normally distributed roughly. To be more precise, the Shapiro-Wilk Normality Test is conducted.


## Causal Analysis

From [Diane Whitmore Schanzenbach Brookings Papers on Education Policy No. 9 (2006/2007), pp. 205-228] we can know, project STAR is a randomized experiment since it ramdomly assigns students to different class types and teachers are also randomly assigned to class types. Therefore, we can make some causal inference if it follows two assumptions:

***Stable unit treatment value assumption***: The potential outcomes for any unit do not vary with the treatments assigned to other units, and, for each unit, there are no different forms or versions of each treatments level, which lead to different potential outcomes.

***Ignorability***: Treatment assignment is independent of the outcomes.

For the first assumption, it means that we could exclude the probability that a teacher was assigned or not assgned to small class does not effect the mean of math grade in other class types. Also, same version of treatment need to be ensured, that means teachers in the class of the one specific type give consistent education of that class type. Both of two points are hold based on the setting of the experiment. For the second assumptions, because of randomized experiment, other factors don't effect our treatments and we don't have the selection bias, the average difference in outcomes between the three groups can only be attributable to treatment.

After verifying two assumptions, we use avarage treatment effect to measure the causal effect. Since there are three class types, we do pairwise comparisons to investigate it. We compare factor level means between each pair. From the above discussion, we can make a conclusion that, small class can cause higher mean scores by different teachers. 


# Discussion

<span style="color:red">Note: </span> Discuss the limitations of the presented projects, and comment on how this project enlightens future research or analysis.

# Appendix I. Reference

[1] C.M. Achilles; Helen Pate Bain; Fred Bellott; Jayne Boyd-Zaharias; Jeremy Finn; John Folger; John Johnston; Elizabeth Word, 2008, “Tennessee’s Student Teacher Achievement Ratio (STAR) project”, https://doi.org/10.7910/DVN/SIWH9F, Harvard Dataverse, V1, UNF:3:Ji2Q+9HCCZAbw3csOdMNdA== [fileUNF]

# Appendix II. Session information
```{r}
print(sessionInfo(), local = FALSE)
```

