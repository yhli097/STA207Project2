---
title: "Project 2: Project STAR II"
output:
  html_document:
    df_print: paged
    fig_caption: yes
    number_sections: yes
  pdf_document: default
  date: "01/31/2020"
---

<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }

</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE,message=FALSE,warning=FALSE)
```
***
Note: The report might be shown to the class as examples if it is done well very or very badly, with your identity redacted. 

***
This Document is the project 2 of Team 7 in STA 207, Winter 2020.

# Group Partners:

1. Bingdao Chen bdchen@ucdavis.edu contribution: explore data and test causal effect

2. Yahui Li yhuli@ucdavis.edu contribution: write down and hold one-way ANOVA model

3. Zihan Wang zihwang@ucdavis.edu contribution: test on difference

4. Jian Shi jnshi@ucdavis.edu contribution: model diagnose

The repository in Github is on https://github.com/yhli097/STA207Project2.git

***

# Introduction

## Background

Tennesses Student/Teacher Achievement Ratio study (Project STAR) was conducted in the late 1980s to evaluate the effect of class size on test scores. The study randomly assigned students to small classes, regular classes, and regular classes with a teacher’s aide. In order to randomize properly, schools were enrolled only if they had enough studybody to have at least one class of each type. Once the schools were enrolled, students were randomly assigned to the three types of classes, and one teacher was randomly assigned to one class.

The primary scientific question of interest is whether there is a treatment effect of class types on math scaled scores across teachers in 1st grade, with the school indicator as the other factor. In this study, we implement exploratory data analysis, two-way anova model, model diagnostics, hypothesis testing. In the end, we conclude our findings and discuss any causal statements that could possibly be made based on our analysis and assumptions, and compare the results between Project 2 and Project 1.

## Statistical questions of interest

To answer the primary scientific question of interest, we propose to fit a two-factors anova model with the quantitative test scores grouped by teacher as the response variable and the class type as well as school as the predictor variable. We will then run our model diagonstics to see if the assumptions of the model hold and test whether or not there is a treatment effect on the test scores.


# Analysis Plan


## Population and study design

According to the description of the dataset, over 7,000 students in 76 schools were randomly assigned into one of three different treatments: small class (13 to 17 students per teacher), regular class (22 to 25 students per teacher), and regular-with-aide class (22 to 25 students with a full-time teacher’s aide). Classroom teachers were also randomly assigned to the classes they would teach. We will only focus on the data about the 1st grade students as study targets[1].

## Descriptive Analysis

First of all, we will pick up all valuable variables we are interested in. To deal with missing value, we will draw plots to show the percentage of missing value for these variables, then decide whether drop the missing value or not. 

We will then explore the math scores grouped by teacher ID. To choose the summary information on math scores in each unit, we will plot different distributions to find a statistic which is the most informative as well as normal-like. 

In the end, we study the treatment of class type as well as school ID. 
Based on different class type as well as school ID, we will confirm whether there is any difference on math scores across teachers not. 


## Two-way Anova Model

In order to investigate whethere there are effects of class types on math scaled scores in 1st grade and minimize the effects of systematic error, randomized block design is uesd, i.e. we creat blocks by different schools. Within blocks, students and teachers are randomly assigned to classed of three types. Therefore, it is possible to assess the effect of different levels of class types without having to worry about variations due to changes of the schools. It should note that there are two factors in this experiment, because we are not interested in the mean scores of one type class in specific school, interaction term is excluded.

The two-way ANOVA model for a randomized block design is shown as follows:

$Y_{ijk} = \mu + \tau_{i}+ \beta{j}+\epsilon_{ijk}, i=1,2,3,~j=1,2,\cdots,76,~k=1,2,\cdots,n_{ij} \text{ with } \epsilon_{ijk} \overset{\mathrm{i.i.d.}}{\sim} \mathcal{N}(0, \sigma^2),$

By notation,

* The index $i$ denotes main factor level. There are 3 main factor levels in our case which are small class type, regular class type and rugular+aid class type.

* The index $j$ denotes blocking facotr level. There are 76 blocking facotr levels in our case which are different schools.

* The index $k$ denotes experimental unit, i.e. teachers of 1st grade. $n_{ij}$ is the number of experimental units in treatment $(i,j)$ from both factors.

* $Y_{ijk}$ denotes $k$-th mean scores of $t$-th class type in $j$_th school.

* $\mu$ denotes the overall mean of the mean scores of math in 1st grade in all treatments.

* $\tau_{i}$ denotes main effect of level $i$ from the class type factor.

* $\beta{j}$ denotes blocking effect of level $j$ from the school id factor.

* $\epsilon_{ijk}$ denotes random errors. 


Moreover, there is a "sum-to-zero" constraint shown in the following :

$$\sum_i \tau_{i} = \sum_j \beta_j = 0$$

Assumptions of two-way ANOVA model specified as follows:

a. the data points are relevant with respect to the scientific question under investigation;
b. the mean of the response variable is influenced additively (if not interaction term) and linearly by the factors;
c. the errors are independent;
d. the errors have the same variance;
e. the errors are normally distributed.


## Model Diagnostics



# Results

<span style="color:red">Note: </span> In this template, we present the unpolished tables and figures generated with generic `r` functions, and we skip all interpretation of the analysis results and the sensitivity analysis.  You can adapt any functions in this section in your report.

## Descriptive Analysis


<span style="color:red">Note: </span> There are many ways to automatically generate summary tables in `R`, of which many would even generate html or latex tables. In this template, we will use the package `qwraps2` as an example ([link](https://cran.r-project.org/web/packages/qwraps2/vignettes/summary-statistics.html)).


The dataset we investigate has 11601 rows and 379 cloumns, and we narrow it down to four columns, that is, g1classtype, g1schid, g1tchid, g1tmathss which are related with math scaled scores in the 1st grade. g1classtype represents the class type of students in 1st grade. g1schid represents school’s id. g1tchid represents teacher’s id. g1tmathss represents math scaled scores of students in 1st grade. Figure1 shows the basic information of four variables.

```{r}
library(tidyverse)
library(ggplot2)
library(kableExtra)
library(gridExtra)
library(ggpubr)
load("./STAR_Students.RData")
data <- data.frame(g1classtype = x$g1classtype, g1schid = x$g1schid, 
                   g1tchid = x$g1tchid, g1tmathss = x$g1tmathss)

# Table code
varsum <- data.frame(Name= c("g1classtype", "g1schid", "g1tchid", "g1tmathss"),
                     Type= c("qualitative variable", "qualitative variable", "qualitative variable", "quantitive variable"), 
                     "The number of levels"= c(3,76,339,NA))
kable(varsum,caption = "Figure1: basic information of variables") %>%
  kable_styling(bootstrap_options = "striped", full_width = F )
```

In Figure 2, the left plot shows the percentage of missing value of four variables are nearly same, and the right plot shows that missing values for these four variables nearly occur at the same rows. It can be explained that because of low grades in kindergarten in STAR project, students quit STAR project and go to another school, or they join STAR project after 1st grade. Because we don’t know how to tackle missing values, considering that we have enough data and believe that it won’t have the significant impact on the results, we drop them directly.

```{r}
#Code for the first plot
missing.values <- data %>%
  gather(key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  group_by(key) %>%
  mutate(total = n()) %>%
  group_by(key, total, isna) %>%
  summarise(num.isna = n()) %>%
  mutate(pct = num.isna / total * 100)

levels <-
    (missing.values  %>% filter(isna == T) %>% arrange(desc(pct)))$key

percentage.plot <- missing.values %>%
      ggplot() +
        geom_bar(aes(x = reorder(key, desc(pct)), 
                     y = pct, fill=isna), 
                 stat = 'identity', alpha=0.8) +
      scale_x_discrete(limits = levels) +
      scale_fill_manual(name = "", 
                        values = c('steelblue', 'tomato3'), labels = c("Present", "Missing")) +
      coord_flip() +
      labs(title = "Figure2: Percentage of missing values", x =
             'Variable', y = "% of missing values")

#Code for the second plot
row.plot <- data %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato3'),
        labels = c("Present", "Missing")) +
    scale_x_discrete(limits = levels) +
    labs(x = "Variable",
           y = "Row Number", title = "Missing values in rows") +
    coord_flip()

#arrange them
grid.arrange(percentage.plot, row.plot, ncol = 2)
```

```{r}
#remove NA
data <- na.omit(data)
data$g1schid <- factor(data$g1schid)
data$g1tchid <- factor(data$g1tchid)
```


Figure 3 shows the frequency number of classtype and school id. We can find that g1classtype data is roughly balanced, and there is one specific school has the frequency number which is much higher than rest of schools.

```{r}
# Figure 3
classbar <- ggplot(data, aes(g1classtype)) +
  geom_bar(fill = "#0073C2FF") +
  theme_pubclean() 


schoolbar <- ggplot(data, aes(g1schid)) +
  geom_bar(fill = "#0073C2FF") +
  theme_pubclean() 


grid.arrange(classbar, schoolbar, ncol = 2)
```

In this project, we are interested in math scaled scores in the 1st grade with teachers as the unit. After verifying each teacher are only employed in specific school and teach one specific class type, we select the mean of math scaled scores of one particular class to judge teachers. Therefore, we have a new dataset which has 339 rows and four columns including g1classtype, g1schid, g1tchid and mean. Figure 4 shows the distribution of the mean of math score by different teacher. It is bell-shaped and roughly closed to normal distribution.


```{r}
data_by_teacher <- data %>%
  group_by(g1classtype,g1schid,g1tchid) %>%
  summarize(mean = mean(g1tmathss))

ggplot(data_by_teacher, aes(x=mean)) + 
  geom_histogram() +
  ggtitle("Figure 4: the mean of math score by different teacher")
```

In Figure 5, we can find that different class types have effects on mean scores of math. Therein, teachers in small class have the higher mean scores of math and teachers in regular class have the lower mean scores of math in general.

```{r}
ggplot(data_by_teacher, aes(x=g1classtype, y=mean)) + 
    geom_boxplot(fill="slateblue", alpha=0.2) +
    labs(title = "Figure 5: The distribution of mean scores of math by class type")
```

## Sensitivity analysis


<span style="color:red">Note: </span>  Show the results of the sensitivity analysis in this section. You can also discuss any new analysis that are not in the interim report. 

### Causal Analysis

From [Diane Whitmore Schanzenbach Brookings Papers on Education Policy No. 9 (2006/2007), pp. 205-228] we can know, project STAR is a randomized experiment since it ramdomly assigns students to different class types and teachers are also randomly assigned to class types. Therefore, we can make some causal inference if it follows two assumptions:

***Stable unit treatment value assumption***: The potential outcomes for any unit do not vary with the treatments assigned to other units, and, for each unit, there are no different forms or versions of each treatments level, which lead to different potential outcomes.

***Ignorability***: Treatment assignment is independent of the outcomes.

For the first assumption, it means that we could exclude the probability that a teacher was assigned or not assgned to small class does not effect the mean of math grade in other class types. Also, same version of treatment need to be ensured, that means teachers in the class of the one specific type give consistent education of that class type. Both of two points are hold based on the setting of the experiment. For the second assumptions, because of randomized experiment, other factors don't effect our treatments and we don't have the selection bias, the average difference in outcomes between the three groups can only be attributable to treatment.

After verifying two assumptions, we use avarage treatment effect to measure the causal effect. Since there are three class types, we do pairwise comparisons to investigate it. We compare factor level means between each pair. From the above discussion, we can make a conclusion that, small class can cause higher mean scores by different teachers. 


# Discussion

<span style="color:red">Note: </span> Discuss the limitations of the presented projects, and comment on how this project enlightens future research or analysis.

# Appendix I. Reference

[1] C.M. Achilles; Helen Pate Bain; Fred Bellott; Jayne Boyd-Zaharias; Jeremy Finn; John Folger; John Johnston; Elizabeth Word, 2008, “Tennessee’s Student Teacher Achievement Ratio (STAR) project”, https://doi.org/10.7910/DVN/SIWH9F, Harvard Dataverse, V1, UNF:3:Ji2Q+9HCCZAbw3csOdMNdA== [fileUNF]

# Appendix II. Session information
```{r}
print(sessionInfo(), local = FALSE)
```

